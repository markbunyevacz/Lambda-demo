#!/usr/bin/env python3
"""
Complete ROCKWOOL PDF Extraction
Extract ALL data from ALL 46 PDFs with complete text, tables, and parameters
Organized by product with readable format
"""

import sys
import json
import csv
import pandas as pd
from pathlib import Path
from datetime import datetime

# Add path for imports
sys.path.append('/app')

try:
    from real_pdf_processor import RealPDFProcessor
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)

def clean_text(text):
    """Clean and format text for better readability"""
    if not text:
        return ""
    
    # Remove excessive whitespace and newlines
    text = ' '.join(text.split())
    
    # Replace encoded characters
    text = text.replace('xE9', '√©').replace('xF6', '√∂').replace('x151', '≈ë')
    text = text.replace('xE1', '√°').replace('xFA', '√∫').replace('xED', '√≠')
    text = text.replace('xF3', '√≥').replace('xFC', '√º').replace('xFD', '√Ω')
    
    return text

def extract_all_pdfs():
    """Extract complete data from ALL 46 ROCKWOOL PDFs"""
    
    print("üîç COMPLETE ROCKWOOL PDF EXTRACTION")
    print("=" * 80)
    print("üìÑ Processing ALL 46 PDFs with complete data extraction")
    print("‚úÖ Claude 3.5 Sonnet AI + PyPDF2/pdfplumber")
    print("‚úÖ Complete text, tables, and parameters")
    print()
    
    try:
        # Initialize processor
        processor = RealPDFProcessor()
        
        # Set PDF directory
        pdf_directory = Path("/app/src/downloads/rockwool_datasheets")
        
        # Get ALL PDF files
        pdf_files = list(pdf_directory.glob("*.pdf"))
        product_pdfs = [f for f in pdf_files if "duplicates" not in str(f)]
        
        print(f"üìÅ Found {len(product_pdfs)} PDF files to process")
        print("=" * 80)
        
        # Data storage
        all_products_data = []
        all_tables_data = []
        extraction_summary = []
        
        # Process ALL PDFs
        for i, pdf_path in enumerate(product_pdfs, 1):
            try:
                print(f"\nüì¶ PROCESSING PDF {i}/{len(product_pdfs)}: {pdf_path.name}")
                print("-" * 70)
                
                # Process PDF
                result = processor.process_pdf(pdf_path)
                
                # Extract basic info
                product_data = {
                    'pdf_number': i,
                    'product_name': result.product_name,
                    'source_file': result.source_filename,
                    'extraction_method': result.extraction_method,
                    'confidence_score': result.confidence_score,
                    'processing_time': result.processing_time,
                    'tables_count': len(result.tables_data),
                    'text_length': len(result.extracted_text)
                }
                
                print(f"‚úÖ Product: {result.product_name}")
                print(f"üìÑ File: {result.source_filename}")
                print(f"üéØ Confidence: {result.confidence_score}")
                print(f"üìä Tables found: {len(result.tables_data)}")
                print(f"üìù Text length: {len(result.extracted_text)} chars")
                
                # Extract and organize text by sections
                full_text = clean_text(result.extracted_text)
                
                # Split text into manageable sections
                text_sections = []
                if full_text:
                    # Split by pages first
                    pages = full_text.split('--- Page')
                    for page_idx, page_text in enumerate(pages):
                        if page_text.strip():
                            text_sections.append({
                                'section': f'Page_{page_idx + 1}',
                                'content': page_text.strip()[:2000]  # First 2000 chars per page
                            })
                
                product_data['text_sections'] = text_sections
                
                # Extract technical specifications
                tech_specs = result.technical_specs
                formatted_specs = {}
                
                if tech_specs:
                    for category, specs in tech_specs.items():
                        if isinstance(specs, dict):
                            formatted_specs[category] = {}
                            for key, value in specs.items():
                                formatted_specs[category][key] = str(value)
                        else:
                            formatted_specs[category] = str(specs)
                
                product_data['technical_specifications'] = formatted_specs
                
                # Extract pricing information
                pricing = result.pricing_info if result.pricing_info else {}
                product_data['pricing_information'] = pricing
                
                # Process ALL tables thoroughly
                tables_detailed = []
                for table_idx, table in enumerate(result.tables_data, 1):
                    table_data = {
                        'product_name': result.product_name,
                        'source_file': result.source_filename,
                        'table_number': table_idx,
                        'page': table.get('page', 'unknown'),
                        'headers': table.get('headers', []),
                        'row_count': len(table.get('data', [])),
                        'complete_data': table.get('data', [])
                    }
                    
                    tables_detailed.append(table_data)
                    
                    # Add each row to CSV data
                    headers = table.get('headers', [])
                    rows = table.get('data', [])
                    
                    for row_idx, row in enumerate(rows, 1):
                        csv_row = {
                            'Product_Name': result.product_name,
                            'Source_File': result.source_filename,
                            'Confidence': result.confidence_score,
                            'Table_Number': table_idx,
                            'Page': table.get('page', 'unknown'),
                            'Row_Number': row_idx,
                            'Total_Rows': len(rows)
                        }
                        
                        # Add header-value pairs
                        for col_idx, cell_value in enumerate(row):
                            header_name = headers[col_idx] if col_idx < len(headers) and headers[col_idx] else f'Column_{col_idx + 1}'
                            csv_row[f'Col_{col_idx + 1}_{header_name}'] = str(cell_value) if cell_value else ''
                        
                        all_tables_data.append(csv_row)
                
                product_data['tables_detailed'] = tables_detailed
                all_products_data.append(product_data)
                
                # Summary for this PDF
                summary = {
                    'pdf_number': i,
                    'product_name': result.product_name,
                    'confidence': result.confidence_score,
                    'tables_count': len(result.tables_data),
                    'text_length': len(result.extracted_text),
                    'processing_time': result.processing_time,
                    'thermal_conductivity': formatted_specs.get('thermal_conductivity', {}).get('value', 'Not found'),
                    'fire_classification': formatted_specs.get('fire_classification', {}).get('value', 'Not found'),
                    'density': formatted_specs.get('density', {}).get('value', 'Not found')
                }
                extraction_summary.append(summary)
                
                print(f"‚úÖ Completed: {result.product_name}")
                
            except Exception as e:
                print(f"‚ùå Error processing {pdf_path.name}: {e}")
                continue
        
        # Save all data
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. Complete products data (JSON)
        products_filename = f'/app/complete_products_data_{timestamp}.json'
        with open(products_filename, 'w', encoding='utf-8') as f:
            json.dump(all_products_data, f, indent=2, ensure_ascii=False)
        
        # 2. All tables data (CSV)
        if all_tables_data:
            tables_filename = f'/app/complete_tables_data_{timestamp}.csv'
            df_tables = pd.DataFrame(all_tables_data)
            df_tables.to_csv(tables_filename, index=False, encoding='utf-8')
        
        # 3. Extraction summary (CSV)
        summary_filename = f'/app/extraction_summary_{timestamp}.csv'
        df_summary = pd.DataFrame(extraction_summary)
        df_summary.to_csv(summary_filename, index=False, encoding='utf-8')
        
        # 4. Readable text report
        report_filename = f'/app/readable_products_report_{timestamp}.txt'
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("COMPLETE ROCKWOOL PRODUCTS EXTRACTION REPORT\n")
            f.write("=" * 80 + "\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total Products: {len(all_products_data)}\n")
            f.write("=" * 80 + "\n\n")
            
            for product in all_products_data:
                f.write(f"\n{'=' * 60}\n")
                f.write(f"PRODUCT: {product['product_name']}\n")
                f.write(f"{'=' * 60}\n")
                f.write(f"Source File: {product['source_file']}\n")
                f.write(f"Confidence: {product['confidence_score']}\n")
                f.write(f"Tables: {product['tables_count']}\n\n")
                
                # Technical specifications
                f.write("TECHNICAL SPECIFICATIONS:\n")
                f.write("-" * 30 + "\n")
                specs = product.get('technical_specifications', {})
                for category, spec_data in specs.items():
                    f.write(f"{category.upper()}:\n")
                    if isinstance(spec_data, dict):
                        for key, value in spec_data.items():
                            f.write(f"  {key}: {value}\n")
                    else:
                        f.write(f"  {spec_data}\n")
                    f.write("\n")
                
                # Text sections
                f.write("EXTRACTED TEXT:\n")
                f.write("-" * 20 + "\n")
                text_sections = product.get('text_sections', [])
                for section in text_sections:
                    f.write(f"\n{section['section']}:\n")
                    f.write(section['content'][:1500] + "\n")  # First 1500 chars
                
                f.write("\n" + "=" * 60 + "\n")
        
        # Final report
        print("\n" + "=" * 80)
        print("üèÅ COMPLETE EXTRACTION FINISHED")
        print("=" * 80)
        print(f"üìÑ Total PDFs processed: {len(all_products_data)}")
        print(f"üìä Total table rows extracted: {len(all_tables_data)}")
        print(f"üìÅ Files created:")
        print(f"   üìã Products data: {products_filename}")
        print(f"   üìä Tables data: {tables_filename}")
        print(f"   üìà Summary: {summary_filename}")
        print(f"   üìñ Readable report: {report_filename}")
        
        print("\n‚úÖ COMPLETE ROCKWOOL PDF EXTRACTION SUCCESSFUL!")
        print("üîç All 46 products with complete text, tables, and parameters")
        print("üìã Organized by product with readable format")
        print("üö´ NO SIMULATIONS - 100% real Claude AI processing")
        
    except Exception as e:
        print(f"‚ùå Extraction failed: {e}")

if __name__ == "__main__":
    extract_all_pdfs() 