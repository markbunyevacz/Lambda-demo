"""
DEMO Scraper IndÃ­tÃ³ Szkript
---------------------------

Ez a szkript felelÅ‘s a DEMO adatgyÅ±jtÃ©si folyamatÃ¡nak elindÃ­tÃ¡sÃ¡Ã©rt.
Sorban meghÃ­vja a scraper-eket, Ã©s az eredmÃ©nyeket elmenti az adatbÃ¡zisba
a DEMO-ra optimalizÃ¡lt `save_product_for_demo` funkciÃ³ segÃ­tsÃ©gÃ©vel.
"""

import asyncio
import logging
from playwright.async_api import async_playwright

# AlapvetÅ‘ logging konfigurÃ¡ciÃ³
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

async def main():
    """
    Elfogja a Rockwool oldal hÃ¡lÃ³zati kÃ©rÃ©seit, hogy megtalÃ¡ljuk a helyes API URL-t.
    """
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False, slow_mo=50)
        page = await browser.new_page()

        # EsemÃ©nyfigyelÅ‘ a hÃ¡lÃ³zati kÃ©rÃ©sek naplÃ³zÃ¡sÃ¡ra
        def log_request(request):
            if "api" in request.url and "search" in request.url:
                logging.info(f" >> API KÃ‰RÃ‰S ELFOGVA: {request.method} {request.url}")

        page.on("request", log_request)

        logging.info("A bÃ¶ngÃ©szÅ‘ elindult. KÃ©rlek, navigÃ¡lj a TermÃ©kadatlapok oldalra.")
        logging.info("Kattints a szÅ±rÅ‘kre, lapozz, amÃ­g meg nem jelennek az API hÃ­vÃ¡sok a konzolon.")
        logging.info("Ha megvan a helyes URL, Ã­rj be egy 'q'-t Ã©s nyomj Entert a bÃ¶ngÃ©szÅ‘ bezÃ¡rÃ¡sÃ¡hoz.")

        await page.goto("https://www.rockwool.com/hu/muszaki-informaciok/termekadatlapok/")
        
        # VÃ¡rakozÃ¡s a felhasznÃ¡lÃ³i beavatkozÃ¡sra
        await asyncio.to_thread(input, "Nyomj Entert a kilÃ©pÃ©shez, miutÃ¡n megvan az URL...\n")

        await browser.close()

# BrightData MCP Demo funkciÃ³k hozzÃ¡adÃ¡sa
async def demo_brightdata_mcp():
    """
    BrightData MCP Agent demo funkciÃ³
    """
    print("\n" + "="*60)
    print("ğŸ¤– BRIGHTDATA MCP AI AGENT DEMO")
    print("="*60)
    
    try:
        from app.agents import BrightDataMCPAgent
        
        # MCP Agent inicializÃ¡lÃ¡s
        agent = BrightDataMCPAgent()
        
        # Kapcsolat teszt
        print("ğŸ“¡ BrightData MCP kapcsolat tesztelÃ©se...")
        connection_test = await agent.test_mcp_connection()
        
        if connection_test['success']:
            print("âœ… BrightData MCP kapcsolat sikeres!")
            print(f"   ğŸ“‹ StÃ¡tusz: {connection_test['message']}")
            
            # AI-vezÃ©relt scraping demo
            print("\nğŸ¯ AI-vezÃ©relt Rockwool scraping demo...")
            
            demo_urls = [
                "https://www.rockwool.hu",
                "https://www.rockwool.hu/termekek/"
            ]
            
            scraped_products = await agent.scrape_rockwool_with_ai(
                demo_urls, 
                "GyÅ±jts Ã¶ssze Rockwool termÃ©k informÃ¡ciÃ³kat a demo szÃ¡mÃ¡ra"
            )
            
            print(f"ğŸ‰ AI scraping eredmÃ©ny: {len(scraped_products)} termÃ©k")
            
            # ElsÅ‘ termÃ©k rÃ©szletei
            if scraped_products:
                sample_product = scraped_products[0]
                print(f"\nğŸ“¦ Minta termÃ©k:")
                print(f"   ğŸ·ï¸  NÃ©v: {sample_product.get('name', 'N/A')}")
                print(f"   ğŸ“ KategÃ³ria: {sample_product.get('category', 'N/A')}")
                print(f"   ğŸ”— URL: {sample_product.get('source_url', 'N/A')}")
            
            # StatisztikÃ¡k
            stats = agent.get_scraping_statistics()
            print(f"\nğŸ“Š AI Scraping statisztikÃ¡k:")
            print(f"   ğŸ¯ Sikeres scraping-ek: {stats['successful_scrapes']}")
            print(f"   âŒ HibÃ¡s scraping-ek: {stats['failed_scrapes']}")
            print(f"   ğŸ“ˆ SikeressÃ©gi arÃ¡ny: {stats.get('success_rate', 0):.1f}%")
            
        else:
            print("âŒ BrightData MCP kapcsolat sikertelen!")
            print(f"   ğŸš« Hiba: {connection_test.get('error', 'Ismeretlen')}")
            print("   ğŸ’¡ EllenÅ‘rizd a kÃ¶rnyezeti vÃ¡ltozÃ³kat (.env.sample)")
    
    except ImportError:
        print("âš ï¸  BrightData MCP dependencies hiÃ¡nyoznak")
        print("   ğŸ“¦ Futtasd: pip install -r requirements.txt")
    except Exception as e:
        print(f"âŒ BrightData MCP demo hiba: {e}")


async def demo_coordinated_scraping():
    """
    KoordinÃ¡lt scraping demo - Ã¶sszes mÃ³dszer tesztelÃ©se
    """
    print("\n" + "="*60)
    print("ğŸ›ï¸  KOORDINÃLT SCRAPING DEMO")
    print("="*60)
    
    try:
        from app.agents import ScrapingCoordinator
        from app.agents.scraping_coordinator import ScrapingStrategy
        
        # Coordinator inicializÃ¡lÃ¡s
        coordinator = ScrapingCoordinator()
        
        # Ã–sszes scraper tesztelÃ©se
        print("ğŸ” Scraper elÃ©rhetÅ‘sÃ©g tesztelÃ©se...")
        test_results = await coordinator.test_all_scrapers()
        
        print(f"\nğŸ“Š Scraper elÃ©rhetÅ‘sÃ©g:")
        print(f"   ğŸ¤– API Scraper: {'âœ…' if test_results['api_scraper']['available'] else 'âŒ'}")
        print(f"   ğŸ§  BrightData MCP: {'âœ…' if test_results['mcp_agent']['available'] else 'âŒ'}")
        
        recommended_strategy = test_results['coordination']['recommended_strategy']
        print(f"   ğŸ’¡ AjÃ¡nlott stratÃ©gia: {recommended_strategy}")
        
        # Demo scraping az ajÃ¡nlott stratÃ©giÃ¡val
        if recommended_strategy != "NONE_AVAILABLE":
            print(f"\nğŸš€ Demo scraping - StratÃ©gia: {recommended_strategy}")
            
            # StratÃ©gia beÃ¡llÃ­tÃ¡s
            if recommended_strategy == ScrapingStrategy.PARALLEL.value:
                coordinator.strategy = ScrapingStrategy.PARALLEL
            elif recommended_strategy == ScrapingStrategy.API_ONLY.value:
                coordinator.strategy = ScrapingStrategy.API_ONLY
            elif recommended_strategy == ScrapingStrategy.MCP_ONLY.value:
                coordinator.strategy = ScrapingStrategy.MCP_ONLY
            
            # Demo scraping
            demo_products = await coordinator.scrape_products(target_input=3)  # 3 termÃ©k limit
            
            print(f"ğŸ‰ KoordinÃ¡lt scraping eredmÃ©ny: {len(demo_products)} termÃ©k")
            
            # Coordination statisztikÃ¡k
            coord_stats = coordinator.get_coordination_statistics()
            print(f"\nğŸ“ˆ KoordinÃ¡ciÃ³ statisztikÃ¡k:")
            print(f"   âœ… API sikerek: {coord_stats['api_successful']}")
            print(f"   ğŸ§  MCP sikerek: {coord_stats['mcp_successful']}")
            print(f"   ğŸ”„ Fallback hasznÃ¡lat: {coord_stats['fallback_used']}")
            print(f"   ğŸ“Š Ã–sszesÃ­tett sikeressÃ©gi arÃ¡ny: {coord_stats['success_rate']:.1f}%")
        else:
            print("âŒ Egyik scraper sem elÃ©rhetÅ‘ - konfigurÃ¡ciÃ³s problÃ©mÃ¡k")
    
    except ImportError:
        print("âš ï¸  KoordinÃ¡ciÃ³ dependencies hiÃ¡nyoznak")
    except Exception as e:
        print(f"âŒ KoordinÃ¡lt scraping demo hiba: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 