---
description: 
globs: 
alwaysApply: true
---
# Lambda.hu √âp√≠t≈ëanyag AI Rendszer - Fejleszt√©si Backlog

## üìã TARTALOMJEGYZ√âK
1. [Projekt √Åttekint√©s](mdc:#1-projekt-√°ttekint√©s)
2. [Aktu√°lis St√°tusz](mdc:#2-aktu√°lis-st√°tusz)
3. [Fejleszt√©si F√°zisok](mdc:#3-fejleszt√©si-f√°zisok)
4. [AI Agent Fejleszt√©sek](mdc:#4-ai-agent-fejleszt√©sek)
5. [K√∂vetkez≈ë L√©p√©sek](mdc:#5-k√∂vetkez≈ë-l√©p√©sek)
6. [Proven Metodol√≥gia](mdc:#6-proven-metodol√≥gia)

---

## 1. PROJEKT √ÅTTEKINT√âS

### 1.1 Minimum Credible Product (MCP) C√©lja
**üéØ C√©l:** Bemutatni a rendszer alapvet≈ë k√©pess√©g√©t: egy felhaszn√°l√≥ term√©szetes nyelven kereshet √©p√≠t≈ëanyagot, a rendszer pedig a naprak√©sz, "scraped" adatok alapj√°n relev√°ns term√©keket √©s AI-alap√∫ szak√©rt≈ëi v√°laszt ad.

### 1.2 MCP Scope
**‚úÖ R√©sze az MCP-nek:**
- **Gy√°rt√≥k**: Csak 1 gy√°rt√≥ (Rockwool) adatainak teljes feldolgoz√°sa
- **Hibrid adatgy≈±jt√©s**: Hagyom√°nyos scraper + **üöÄ BrightData MCP AI** (48 tools, CAPTCHA solving)
- **Adatb√°zisok**: Struktur√°lt adatb√°zis (PostgreSQL) √©s vektor adatb√°zis (Chroma)
- **Keres√©s**: Term√©szetes nyelv≈± keres√©s (RAG pipeline) √©s egyszer≈± term√©klista
- **UI**: Egy keres≈ëmez≈ë, egy AI chat ablak √©s egy term√©klista megjelen√≠t≈ë

**‚ùå Nem r√©sze az MCP-nek:**
- T√∂bb gy√°rt√≥ t√°mogat√°sa
- Aj√°nlatk√©sz√≠t≈ë modul
- Komplex sz≈±r≈ëk
- Felhaszn√°l√≥i fi√≥kok

---

## 2. AKTU√ÅLIS ST√ÅTUSZ

### 2.1 ‚úÖ PRODUCTION COMPLETE (Verified & Tested)
**Total: 2 major modules completed to production standard**

#### **Rockwool Term√©kadatlap Scraper** ‚úÖ PRODUCTION COMPLETE
- **Evidence**: 45 product datasheets downloaded with 100% success rate
- **Tested**: `rockwool_scraper_final.py` - End-to-end production testing completed
- **Location**: `downloads/final_test/` (34 unique) + `downloads/final_test/duplicates/` (11 duplicates)
- **Features**: Fresh debug file refresh, smart duplicate handling, zero data loss
- **Performance**: 45 products found, 45 downloads successful, 0 failed

#### **Rockwool √Årlist√°k Scraper** ‚úÖ PRODUCTION COMPLETE
- **Evidence**: 12 brochures and pricelists downloaded with 100% success rate
- **Tested**: `backend/app/scrapers/rockwool_final/brochure_scraper.py`
- **Location**: `downloads/rockwool_brochures/` (12 unique files, 0 duplicates)
- **Key Documents**: ROCKWOOL √Årlista 2025 (8.48 MB), ProRox √Årlista (6.61 MB)
- **Enhancement**: Applied proven success methodology

### 2.2 ‚úÖ INFRASTRUCTURE READY (Awaiting Verification)
**Total: 42 components with infrastructure completed**

#### **Alapinfrastrukt√∫ra** ‚úÖ
- Projektstrukt√∫ra fel√°ll√≠t√°sa (Backend, Docker)
- Docker-compose konfigur√°ci√≥ (FastAPI, PostgreSQL, Redis)
- Adatb√°zis s√©m√°k √©s SQLAlchemy modellek
- Alapvet≈ë FastAPI alkalmaz√°s (CORS √©s DB kapcsolattal)
- Alapvet≈ë Next.js/React frontend v√°z

#### **BrightData MCP AI Scraping Rendszer** ‚úÖ INFRASTRUCTURE READY
- **Evidence**: Connection to MCP server successful, all 48 tools loaded
- **Tested**: Standalone scripts confirmed MCP server initialization
- **Requires**: Human verification for full AI-driven scraping task

#### **Adatb√°zis √©s Automatiz√°l√°s** ‚úÖ INFRASTRUCTURE READY
- **Adatb√°zis Integr√°ci√≥s Logika**: All data models and integration services defined
- **Celery √©s Celery Beat**: All tasks and scheduling configurations defined
- **Integr√°ci√≥s Tesztel√©s**: `test_integration.py` framework exists

### 2.3 üîÑ IN DEVELOPMENT (Current Priority)
**Immediate Next Steps:**
1. **Client-Specific Architecture** - Modular design implementation
2. **Factory Pattern Implementation** - Reusable scraper framework
3. **Database Integration Testing** - Save 57 Rockwool documents to PostgreSQL

### 2.4 üîç AWAITING HUMAN VERIFICATION
**Critical Items Requiring Testing:**
1. **BrightData MCP Integration** - Production testing required
2. **Database Integration** - Large-scale data processing verification
3. **Celery Automation** - Production scheduling verification

---

## 3. FEJLESZT√âSI F√ÅZISOK

### 3.1 F√°zis 1: Alapoz√°s √©s Infrastrukt√∫ra ‚úÖ VERIFIED COMPLETE
- [x] Projektstrukt√∫ra fel√°ll√≠t√°sa (Backend, Docker)
- [x] Docker-compose konfigur√°ci√≥ (FastAPI, PostgreSQL, Redis)
- [x] Adatb√°zis s√©m√°k √©s SQLAlchemy modellek l√©trehoz√°sa
- [x] Alapvet≈ë FastAPI alkalmaz√°s l√©trehoz√°sa, CORS √©s DB kapcsolattal
- [x] Alapvet≈ë Next.js/React frontend v√°z l√©trehoz√°sa

### 3.2 F√°zis 2: Adat-pipeline √©s Web Scraping ‚úÖ PRODUCTION READY
- [x] **Rockwool Term√©kadatlap Scraper** ‚úÖ PRODUCTION COMPLETE
- [x] **Rockwool √Årlist√°k Scraper** ‚úÖ PRODUCTION COMPLETE
- [x] **BrightData MCP AI Scraping Rendszer** ‚úÖ INFRASTRUCTURE READY
- [x] **Adatb√°zis Integr√°ci√≥s Logika** ‚úÖ INFRASTRUCTURE READY
- [x] **Celery √©s Celery Beat Id≈ëz√≠t√©s** ‚úÖ INFRASTRUCTURE READY
- [x] **Integr√°ci√≥s Tesztel√©s** ‚úÖ INFRASTRUCTURE READY
- [ ] **Leier scraper implement√°ci√≥ja** üîÑ PLANNED
- [ ] **Baumit scraper implement√°ci√≥ja** üîÑ PLANNED

### 3.3 F√°zis 3: AI Modul - RAG Pipeline üîÑ PLANNED
#### **Hibrid Vektor Adatb√°zis**
- [ ] **Hibrid Chroma vektor adatb√°zis** inicializ√°l√°sa √©s perziszt√°l√°sa
- [ ] Hagyom√°nyos scraped adatok vektoriz√°l√°sa
- [ ] **üöÄ AI-enhanced term√©kle√≠r√°sok** indexel√©se BrightData MCP eredm√©nyekb≈ël
- [ ] Magyar nyelvi embeddings optimaliz√°l√°s

#### **LangChain Integr√°ci√≥**
- [ ] **LangChain integr√°ci√≥ tov√°bbfejlesztve** √©s `BuildingMaterialsAI` service l√©trehoz√°sa
- [ ] **AI scraping context** integr√°l√°sa a RAG pipeline-ba
- [ ] **Intelligent retrieval** - forr√°s preferenci√°k (API vs MCP AI)
- [ ] **Real-time scraping capability** term√©szetes nyelv≈± k√©r√©sekre

#### **AI K√©pess√©gek**
- [ ] Term√©kadatok automatikus vektoriz√°l√°sa √©s indexel√©se (hibrid forr√°sok)
- [ ] Q&A l√°nc l√©trehoz√°sa a magyar nyelv≈±, √©p√≠t√©szeti szak√©rt≈ëi prompt-tal
- [ ] **üöÄ AI confidence score** alap√∫ term√©k rangsorol√°s √©s v√°laszmin≈ës√©g
- [ ] Kompatibilit√°s-ellen≈ërz≈ë logika alapjainak implement√°l√°sa (`check_system_compatibility`)

### 3.4 F√°zis 4: Backend API √©s Frontend Integr√°ci√≥ üîÑ PLANNED
#### **Hibrid API V√©gpontok**
- [ ] **Hibrid term√©kkeres≈ë API** v√©gpont l√©trehoz√°sa (sz√∂veges keres√©s + sz≈±r√©s)
- [ ] **üöÄ `/api/search/hybrid`** - Kombin√°lja hagyom√°nyos + AI eredm√©nyeket
- [ ] **üöÄ `/api/scraping/intelligent`** - Real-time AI scraping k√©r√©sre
- [ ] **üöÄ `/api/scraping/status`** - AI scraping feladatok monitoring

#### **AI Chat API**
- [ ] **AI Chat API tov√°bbfejlesztve** (`get_product_recommendations`)
- [ ] **üöÄ `/api/ai/analyze-product`** - Term√©k AI elemz√©s k√©r√©sre
- [ ] BrightData MCP eredm√©nyek integr√°l√°sa v√°laszokba
- [ ] Kompatibilit√°s-ellen≈ërz≈ë API v√©gpont l√©trehoz√°sa (AI-enhanced)

#### **Frontend Fejleszt√©sek**
- [ ] **Frontend: AI-enhanced term√©kkeres≈ë** interface fejleszt√©se
- [ ] **üöÄ Real-time scraping status** indicator
- [ ] **üöÄ AI confidence score** megjelen√≠t√©s term√©kekn√©l
- [ ] **üöÄ "K√©rd el AI-t√≥l √∫j term√©keket"** funkci√≥
- [ ] Frontend: AI Chat komponens fejleszt√©se √©s bek√∂t√©se
- [ ] Frontend: Term√©k adatlap √©s √∂sszehasonl√≠t√≥ komponens fejleszt√©se
- [ ] **üöÄ Scraping admin panel** - strat√©gia v√°lt√°s, monitoring (fejleszt≈ëknek)

### 3.5 F√°zis 5: Aj√°nlatk√©sz√≠t≈ë Modul üîÑ PLANNED
- [ ] `quotes` adatb√°zis t√°bla √©s SQLAlchemy modell
- [ ] `QuoteCalculator` service implement√°l√°sa (√°rkalkul√°ci√≥, vesztes√©gsz√°m√≠t√°s)
- [ ] Aj√°nlatk√©sz√≠t≈ë API v√©gpontok (l√©trehoz√°s, lek√©rdez√©s)
- [ ] PDF gener√°l√≥ modul integr√°l√°sa (ReportLab)
- [ ] Email k√ºld≈ë szolg√°ltat√°s integr√°ci√≥ja
- [ ] Frontend: Aj√°nlatk√©sz√≠t≈ë UI (kos√°r, v√©gleges√≠t√©s)

### 3.6 F√°zis 6: Finaliz√°l√°s √©s Deployment üîÑ PLANNED
- [ ] Teljes k√∂r≈± API √©s frontend tesztel√©s (pytest, Jest/Playwright)
- [ ] `Dockerfile`-ok finomhangol√°sa √©les k√∂rnyezetre
- [ ] CI/CD pipeline alapjainak l√©trehoz√°sa (pl. GitHub Actions)
- [ ] R√©szletes dokument√°ci√≥ (API Swagger, README)
- [ ] Felhaszn√°l√≥i tesztel√©s √©s visszajelz√©sek feldolgoz√°sa

---

## 4. AI AGENT FEJLESZT√âSEK

### 4.1 ü§ñ AI Agent Implement√°ci√≥s Backlog

#### **Adatfeldolgoz√≥ Agent** (`DataProcessingAgent`)
- [ ] Raw adatok normaliz√°l√°sa √©s tiszt√≠t√°sa
- [ ] Duplik√°tumok intelligens elt√°vol√≠t√°sa
- [ ] Kategoriz√°l√°s √©s c√≠mk√©z√©s automatiz√°l√°sa
- [ ] Min≈ës√©gbiztos√≠t√°si pipeline implement√°l√°sa

#### **Aj√°nl√°si Agent - RAG** (`RecommendationAgent`)
- [ ] Term√©k √∂sszehasonl√≠t√°si logika
- [ ] Szem√©lyre szabott aj√°nl√°sok gener√°l√°sa
- [ ] RAG alap√∫ v√°laszgener√°l√°s implement√°l√°sa
- [ ] Kontextus meg√©rt√©s √©s mem√≥ria kezel√©s

#### **√Årfigyel≈ë Agent** (`PriceMonitoringAgent`)
- [ ] √År tracking k√ºl√∂nb√∂z≈ë forr√°sokon kereszt√ºl
- [ ] Trend anal√≠zis √©s el≈ërejelz√©s
- [ ] Riaszt√°sok gener√°l√°sa √°r v√°ltoz√°sokra
- [ ] Historikus adatok kezel√©se √©s archiv√°l√°sa

#### **Kompatibilit√°si Agent** (`CompatibilityAgent`)
- [ ] Term√©kek kompatibilit√°s√°nak automatikus ellen≈ërz√©se
- [ ] M≈±szaki specifik√°ci√≥k √∂sszehasonl√≠t√°sa
- [ ] Alkalmaz√°si ter√ºletek elemz√©se
- [ ] Szabv√°nyok √©s el≈ë√≠r√°sok ellen≈ërz√©se

### 4.2 üèóÔ∏è Agent Infrastrukt√∫ra Fejleszt√©sek

#### **Event Bus Integr√°ci√≥** (`AgentEventBus`)
- [ ] Agent-to-agent kommunik√°ci√≥s rendszer
- [ ] Event subscription/publishing mechanizmus
- [ ] Message queuing (Redis) integr√°ci√≥
- [ ] Error handling √©s retry logika

#### **Agent Health Monitoring** (`AgentHealthMonitor`)
- [ ] Heartbeat ellen≈ërz√©si rendszer
- [ ] Performance metrik√°k gy≈±jt√©se
- [ ] Resource haszn√°lat tracking
- [ ] Automatikus √∫jraind√≠t√°si mechanizmus

#### **Agent Lifecycle Management**
- [ ] State management (INITIALIZING ‚Üí IDLE ‚Üí WORKING ‚Üí ERROR/STOPPING ‚Üí STOPPED)
- [ ] Graceful shutdown √©s restart
- [ ] Configuration hot-reload
- [ ] Service discovery implement√°l√°sa

#### **Performance Metrik√°k Rendszer** (`AgentMetrics`)
- [ ] Task completion rate tracking
- [ ] Average response time m√©r√©se
- [ ] Error rate monitoring
- [ ] Resource consumption analysis
- [ ] System-wide metrik√°k (total active agents, message throughput)

### 4.3 üõ†Ô∏è Fejleszt≈ëi Tooling √©s Template-ek

#### **Agent Template Script** implement√°l√°sa
- [ ] `python scripts/create_agent.py --name MyNewAgent --type data_processing`
- [ ] Skeleton k√≥dgener√°l√°s
- [ ] Konfigur√°ci√≥ template-ek
- [ ] Testing boilerplate gener√°l√°sa

#### **Integration Checklist** automatiz√°l√°sa
- [ ] Agent oszt√°ly implement√°l√°s ellen≈ërz√©se
- [ ] Health check endpoint valid√°l√°sa
- [ ] Metrics collection tesztel√©se
- [ ] Unit √©s integration tesztek futtat√°sa

#### **Migration Protocol** implement√°l√°sa
- [ ] Client-specific architecture √°t√°ll√°si l√©p√©sek
- [ ] Modular scraper design pattern alkalmaz√°sa
- [ ] Factory pattern implement√°l√°sa (`ClientFactory.create_scraper()`)
- [ ] Clean API interface l√©trehoz√°sa

---

## 5. K√ñVETKEZ≈ê L√âP√âSEK

### 5.1 üéØ Azonnal Megval√≥s√≠tand√≥ (H√©t 1-2)
1. **Database Integration Testing** - Save 57 Rockwool documents to PostgreSQL
2. **BrightData MCP Production Testing** - Full AI-driven scraping task verification
3. **Client-Specific Architecture** - Modular design implementation

### 5.2 üîÑ R√∂vid T√°v√∫ (H√©t 3-4)
1. **Factory Pattern Implementation** - Reusable scraper framework
2. **Celery Automation Testing** - Production scheduling verification
3. **RAG Pipeline Foundation** - Chroma vector database initialization

### 5.3 üìã K√∂zepes T√°v√∫ (H√©t 5-8)
1. **AI Agent Infrastructure** - Event Bus, Health Monitoring
2. **Hibrid API Endpoints** - Intelligent search and scraping
3. **Frontend AI Integration** - Real-time status, confidence scores

---

## 6. PROVEN METODOL√ìGIA

### 6.1 üéØ SUCCESS PATTERN IDENTIFIED
1. **Evidence-First Approach** - Start with existing working data (debug files)
2. **Incremental Testing** - Test each component individually before integration
3. **Zero Data Loss** - Implement duplicate handling, never overwrite
4. **Fresh Data Strategy** - Auto-refresh content before scraping
5. **Production Validation** - Complete end-to-end testing before marking complete

### 6.2 üîë Key Insights
**Working Code ‚â† Infrastructure Existence**
- Only mark items as PRODUCTION COMPLETE after successful end-to-end testing
- Use "INFRASTRUCTURE READY" for components that exist but lack verification
- Prioritize functional validation over feature expansion

### 6.3 üìä St√°tusz Kateg√≥ri√°k
- **‚úÖ PRODUCTION COMPLETE**: Verified & Tested, ready for production use
- **‚úÖ INFRASTRUCTURE READY**: Code exists, basic tests pass, awaiting verification
- **üîÑ IN DEVELOPMENT**: Active development in progress
- **üîç AWAITING VERIFICATION**: Human testing required
- **üîÑ PLANNED**: Design/requirements ready, not yet started

---

## üìö GYORS REFERENCIA

### Legfontosabb St√°tuszok
- **Production Complete**: 2 modulok (Rockwool scrapers)
- **Infrastructure Ready**: 42 komponens
- **Awaiting Verification**: 3 kritikus elem
- **Planned**: 22+ komponens

### K√∂vetkez≈ë Milestone
**üéØ Database Integration Completion** - 57 Rockwool dokumentum PostgreSQL-be ment√©se