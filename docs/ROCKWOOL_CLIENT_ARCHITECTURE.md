# Rockwool Client-Specific Scraping Architecture

## ðŸŽ¯ **Executive Summary**

This document defines the **modular, client-specific architecture** for the Rockwool scraping solution within the Lambda.hu platform. The architecture ensures **separation of concerns**, **reusability**, and **technical scalability** for handling multiple clients.

## ðŸ—ï¸ **Architecture Overview**

```
clients/
â”œâ”€â”€ rockwool/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ endpoints.py          # Rockwool-specific URLs
â”‚   â”‚   â”œâ”€â”€ selectors.py          # CSS/XPath selectors
â”‚   â”‚   â”œâ”€â”€ parsing_rules.py      # HTML parsing logic
â”‚   â”‚   â””â”€â”€ product_schemas.py    # Data validation schemas
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py               # Abstract base scraper
â”‚   â”‚   â”œâ”€â”€ termekadatlapok.py    # Product datasheets scraper
â”‚   â”‚   â”œâ”€â”€ arlistak.py           # Pricelists scraper
â”‚   â”‚   â””â”€â”€ brochures.py          # Brochures scraper
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ product_parser.py     # O74DocumentationList parser
â”‚   â”‚   â”œâ”€â”€ category_mapper.py    # Category normalization
â”‚   â”‚   â””â”€â”€ data_validator.py     # Rockwool-specific validation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ product.py            # Rockwool product data model
â”‚   â”‚   â”œâ”€â”€ category.py           # Category data model
â”‚   â”‚   â””â”€â”€ download_result.py    # Download result model
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_manager.py       # PDF download & storage
â”‚   â”‚   â”œâ”€â”€ cookie_handler.py     # Cookie consent bypass
â”‚   â”‚   â””â”€â”€ url_builder.py        # URL construction utilities
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py             # Rockwool API client
â”‚   â”‚   â””â”€â”€ endpoints.py          # REST API endpoints
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_scrapers.py
â”‚   â”‚   â”œâ”€â”€ test_parsers.py
â”‚   â”‚   â””â”€â”€ fixtures/
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ api_reference.md
â”‚   â”‚   â”œâ”€â”€ data_flow.md
â”‚   â”‚   â””â”€â”€ troubleshooting.md
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scraper.py            # Abstract scraper interface
â”‚   â”‚   â”œâ”€â”€ parser.py             # Abstract parser interface
â”‚   â”‚   â””â”€â”€ client.py             # Abstract client interface
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ brightdata_client.py  # BrightData MCP wrapper
â”‚   â”‚   â””â”€â”€ session_manager.py    # MCP session management
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_storage.py       # File system storage
â”‚   â”‚   â””â”€â”€ database_storage.py   # Database storage
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py            # Centralized logging
â”‚       â”œâ”€â”€ config.py             # Configuration management
â”‚       â””â”€â”€ exceptions.py         # Custom exception classes
â””â”€â”€ factory/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ client_factory.py         # Client factory pattern
    â””â”€â”€ scraper_registry.py       # Scraper registration
```

## ðŸ”§ **Core Components**

### 1. **Client-Specific Configuration**

```python
# clients/rockwool/config/endpoints.py
from dataclasses import dataclass

@dataclass
class RockwoolEndpoints:
    """Rockwool-specific URL endpoints"""
    BASE_URL: str = "https://www.rockwool.com"
    TERMEKADATLAPOK: str = "/hu/muszaki-informaciok/termekadatlapok/"
    ARLISTAK: str = "/hu/muszaki-informaciok/arlistak-es-prospektusok/"
    
    @property
    def full_termekadatlapok_url(self) -> str:
        return f"{self.BASE_URL}{self.TERMEKADATLAPOK}"
```

### 2. **Abstract Base Classes**

```python
# shared/base/scraper.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

class BaseScraper(ABC):
    """Abstract base class for all client scrapers"""
    
    def __init__(self, client_name: str, config: Dict[str, Any]):
        self.client_name = client_name
        self.config = config
        self.session = None
    
    @abstractmethod
    async def scrape(self, url: str, **kwargs):
        """Main scraping method - must be implemented by clients"""
        pass
```

This architecture ensures **separation of concerns**, **reusability**, and **technical scalability** for the Rockwool client while being easily extensible for future clients. 